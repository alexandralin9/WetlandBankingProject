{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snibb\\AppData\\Local\\Temp\\ipykernel_9788\\3267924886.py:153: DtypeWarning: Columns (19,31,32,34,35,38,41,53,56,58,60,61,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  withdrawals_df = pd.read_csv(withdrawals_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned names\n",
      "['mud slough' 'muddy creek' 'one horse slough sold out' ...\n",
      " 'wi washington wisdot willow creek stream and wetland'\n",
      " 'succor creek pending' 'north fork payette river pending']\n",
      "0                     virginia aquatic resources trust fund\n",
      "1                     virginia aquatic resources trust fund\n",
      "2                     virginia aquatic resources trust fund\n",
      "3                     virginia aquatic resources trust fund\n",
      "4                     virginia aquatic resources trust fund\n",
      "                                ...                        \n",
      "104109                            port fourchon single user\n",
      "104110                          buffalo quarry conservation\n",
      "104111                          buffalo quarry conservation\n",
      "104112    mn itasca s3734t1785 brink farms phase ii mndo...\n",
      "104113    mn itasca s3734t1785 brink farms phase ii mndo...\n",
      "Name: Clean_Name, Length: 104114, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104114/104114 [00:29<00:00, 3545.83it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Analysis:\n",
      "Total Records: 106110\n",
      "Matched Records: 97929\n",
      "Match Rate: 92.29%\n",
      "Score Distribution:\n",
      "count    106110.000000\n",
      "mean         92.234930\n",
      "std          26.675547\n",
      "min           0.000000\n",
      "25%         100.000000\n",
      "50%         100.000000\n",
      "75%         100.000000\n",
      "max         100.000000\n",
      "Name: Match_Score, dtype: float64\n",
      "Sample matches at different score levels:\n",
      "Score >= 100:\n",
      "                                     Name  \\\n",
      "7431  Keys Environmental Restoration Fund   \n",
      "7432  Keys Environmental Restoration Fund   \n",
      "8520                           Mud Slough   \n",
      "\n",
      "                           Original_Bank_Name  Match_Score  \n",
      "7431  ILF Keys Environmental Restoration Fund        100.0  \n",
      "7432  ILF Keys Environmental Restoration Fund        100.0  \n",
      "8520                               Mud Slough        100.0  \n",
      "Score >= 90:\n",
      "                       Name          Original_Bank_Name  Match_Score\n",
      "1737  The Conservation Fund  The Conservation Fund/AR-1    93.333333\n",
      "1738  The Conservation Fund  The Conservation Fund/AR-1    93.333333\n",
      "1739  The Conservation Fund  The Conservation Fund/AR-1    93.333333\n",
      "Score >= 80:\n",
      "                       Name          Original_Bank_Name  Match_Score\n",
      "1737  The Conservation Fund  The Conservation Fund/AR-1    93.333333\n",
      "1738  The Conservation Fund  The Conservation Fund/AR-1    93.333333\n",
      "1739  The Conservation Fund  The Conservation Fund/AR-1    93.333333\n",
      "Results saved to 'matched_results.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from fuzzywuzzy import fuzz, process\n",
    "from rapidfuzz import fuzz, process, utils\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def clean_bank_name(name):\n",
    "    \"\"\"\n",
    "    Clean and standardize bank names for better matching.\n",
    "    \"\"\"\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to string and lowercase\n",
    "    name = str(name).lower()\n",
    "    \n",
    "    # Remove common suffixes and prefixes\n",
    "    remove_terms = [\n",
    "        'mitigation bank', 'bank', 'mb', 'conservation bank', 'cb', \n",
    "        'in-lieu fee program', 'ilf', 'program', 'umbrella', \n",
    "        'conservation area', 'preserve', 'restoration'\n",
    "    ]\n",
    "    \n",
    "    for term in remove_terms:\n",
    "        name = name.replace(term, '')\n",
    "    \n",
    "    # Remove special characters and extra spaces\n",
    "    name = re.sub(r'[^a-z0-9\\s]', '', name)\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    \n",
    "    return name\n",
    "\n",
    "def match_bank_names(withdrawals_df, banks_df, threshold=80):\n",
    "    \"\"\"\n",
    "    Match bank names between withdrawals and banks dataframes using fuzzy matching.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    withdrawals_df : pandas DataFrame\n",
    "        DataFrame containing withdrawal records\n",
    "    banks_df : pandas DataFrame\n",
    "        DataFrame containing bank records\n",
    "    threshold : int\n",
    "        Minimum similarity score to consider a match (0-100)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas DataFrame\n",
    "        Original withdrawals DataFrame with matched bank names and scores\n",
    "    \"\"\"\n",
    "    # Clean bank names in both dataframes\n",
    "    withdrawals_df['Clean_Name'] = withdrawals_df['Name'].apply(clean_bank_name)\n",
    "    banks_df['Clean_Name'] = banks_df['Name'].apply(clean_bank_name)\n",
    "    print(\"Cleaned names\")\n",
    "    \n",
    "    # Create a dictionary of unique clean bank names\n",
    "    unique_bank_names = banks_df['Clean_Name'].unique()\n",
    "    print(unique_bank_names)\n",
    "    print(withdrawals_df['Clean_Name'])\n",
    "    \n",
    "    # Function to find best match for each withdrawal\n",
    "    best_matches = {}\n",
    "    def find_best_match(name):\n",
    "        if pd.isna(name) or name == \"\":\n",
    "            return pd.Series({'Matched_Bank_Name': np.nan, 'Match_Score': 0})\n",
    "\n",
    "        if name in best_matches:\n",
    "            return best_matches[name]\n",
    "        \n",
    "        best_match = process.extractOne(\n",
    "            name,\n",
    "            unique_bank_names,\n",
    "            scorer=fuzz.token_sort_ratio,\n",
    "            score_cutoff=threshold,\n",
    "            # scorer=fuzz.WRatio,\n",
    "            processor=utils.default_process\n",
    "        )\n",
    "        \n",
    "        if best_match:\n",
    "            return_val = pd.Series({\n",
    "                'Matched_Bank_Name': best_match[0],\n",
    "                'Match_Score': best_match[1]\n",
    "            })\n",
    "            best_matches[name] = return_val\n",
    "            return return_val\n",
    "        return pd.Series({'Matched_Bank_Name': np.nan, 'Match_Score': 0})\n",
    "    \n",
    "    # Apply matching\n",
    "    match_results = withdrawals_df['Clean_Name'].progress_apply(find_best_match)\n",
    "    print('Matched results')\n",
    "    \n",
    "    # Add results to original dataframe\n",
    "    result_df = withdrawals_df.copy()\n",
    "    result_df['Matched_Bank_Name'] = match_results['Matched_Bank_Name']\n",
    "    result_df['Match_Score'] = match_results['Match_Score']\n",
    "\n",
    "    # Merge latitude and longitude from banks_df\n",
    "    lat_lon_df = banks_df[['Clean_Name', 'Latitude', 'Longitude']].drop_duplicates()\n",
    "    \n",
    "    # Merge on matched bank names to pull latitude and longitude\n",
    "    result_df = result_df.merge(lat_lon_df, left_on='Matched_Bank_Name', right_on='Clean_Name', how='left')\n",
    "\n",
    "    # Drop duplicate 'Clean_Name' column after the merge\n",
    "    result_df = result_df.drop(columns=['Clean_Name_y'])\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    result_df = result_df.rename(columns={\n",
    "        'Clean_Name_x': 'Clean_Name',\n",
    "        'Latitude': 'Matched_Latitude',\n",
    "        'Longitude': 'Matched_Longitude'\n",
    "    })\n",
    "    \n",
    "    # Get original bank names and details for matches\n",
    "    bank_name_map = banks_df.set_index('Clean_Name')['Name'].to_dict()\n",
    "    result_df['Original_Bank_Name'] = result_df['Matched_Bank_Name'].map(bank_name_map)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def analyze_matching_results(matched_df):\n",
    "    \"\"\"\n",
    "    Analyze the results of the matching process.\n",
    "    \"\"\"\n",
    "    total_records = len(matched_df)\n",
    "    matched_records = matched_df['Matched_Bank_Name'].notna().sum()\n",
    "    match_rate = (matched_records / total_records) * 100\n",
    "    \n",
    "    score_distribution = matched_df['Match_Score'].describe()\n",
    "    \n",
    "    print(f\"Matching Analysis:\")\n",
    "    print(f\"Total Records: {total_records}\")\n",
    "    print(f\"Matched Records: {matched_records}\")\n",
    "    print(f\"Match Rate: {match_rate:.2f}%\")\n",
    "    print(\"Score Distribution:\")\n",
    "    print(score_distribution)\n",
    "    \n",
    "    # Sample of matches at different score levels\n",
    "    print(\"Sample matches at different score levels:\")\n",
    "    for score in [100, 90, 80]:\n",
    "        sample = matched_df[matched_df['Match_Score'] >= score].head(3)\n",
    "        print(f\"Score >= {score}:\")\n",
    "        print(sample[['Name', 'Original_Bank_Name', 'Match_Score']])\n",
    "\n",
    "\n",
    "# Load your data\n",
    "# withdrawals_file = 'withdrawals.csv'  # Replace with your file\n",
    "# banks_file = 'banks.csv'  # Replace with your file\n",
    "withdrawals_file = 'Bank and ILF Program Credit Tracking 2024_10_16.csv'\n",
    "banks_file = 'All banks .xlsx'  # Replace with your file\n",
    "tqdm.pandas()\n",
    "\n",
    "try:\n",
    "    withdrawals_df = pd.read_csv(withdrawals_file)\n",
    "    banks_df = pd.read_excel(banks_file)\n",
    "    \n",
    "    # Perform matching\n",
    "    matched_results = match_bank_names(withdrawals_df, banks_df)\n",
    "    \n",
    "    # Analyze results\n",
    "    analyze_matching_results(matched_results)\n",
    "    \n",
    "    # Save results\n",
    "    matched_results.to_csv('matched_results.csv', index=False)\n",
    "    print(\"Results saved to 'matched_results.csv'\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Please ensure input files exist and are in the correct location.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95933\n",
      "104114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snibb\\AppData\\Local\\Temp\\ipykernel_9788\\3084049197.py:1: DtypeWarning: Columns (19,31,32,34,35,38,41,53,56,58,60,61,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  matches_df = pd.read_csv('matched_results.csv')\n"
     ]
    }
   ],
   "source": [
    "matches_df = pd.read_csv('matched_results.csv')\n",
    "\n",
    "# count number of matches by score > 0\n",
    "print(len(matches_df[matches_df['Match_Score'] > 0]))\n",
    "\n",
    "# count number of total rows\n",
    "print(len(matches_df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
